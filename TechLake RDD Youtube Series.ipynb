{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5f817e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=DmJXgWmq3pY&list=PL50mYnndduIHGS49Q_tve1f7aW4NHjvgQ&index=1\n",
    "#Completed all the rdd related video \n",
    "#Still need to check the one with databricks in this playlist\n",
    "#https://www.youtube.com/watch?v=2otrn2mvlSQ\n",
    "#Use the above link and move to next tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbc382bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/21 12:55:35 WARN Utils: Your hostname, laptop resolves to a loopback address: 127.0.0.1; using 192.168.0.9 instead (on interface wlp3s0)\n",
      "23/06/21 12:55:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/21 12:55:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce1e5f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchDayResults_rdd = sc.textFile(\"/home/desai/DE/Files/pl_stats_2023/2023_matchday_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4457484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sl.no,fixture.id,fixture.date,teams.home.id,teams.home.name,teams.home.winner,teams.away.id,teams.away.name,teams.away.winner,goals.home,goals.away\n",
      "0,867946,2022-08-05T19:00:00+00:00,52,Crystal Palace,False,42,Arsenal,True,0,2\n",
      "1,867947,2022-08-06T11:30:00+00:00,36,Fulham,,40,Liverpool,,2,2\n",
      "2,867948,2022-08-06T14:00:00+00:00,35,Bournemouth,True,66,Aston Villa,False,2,0\n",
      "3,867949,2022-08-06T14:00:00+00:00,63,Leeds,True,39,Wolves,False,2,1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lines = matchDayResults_rdd.take(5)\n",
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbe49b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'a': 2, 1: 2, 3: 2, 'b': 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= sc.parallelize(['a',1,3,1,3,'a','b'])\n",
    "x.countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49ba4f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fold\n",
    "from operator import add\n",
    "numbers_rdd = sc.parallelize(range(1, 11), numSlices=3)\n",
    "numbers_rdd.fold(0,add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32967f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6], [7, 8, 9, 10]]\n",
      "Partition 1 sum: 0\n",
      "Partition 2 sum: 1\n",
      "Partition 3 sum: 3\n",
      "Partition 4 sum: 6\n",
      "Partition 5 sum: 0\n",
      "Partition 6 sum: 4\n",
      "Partition 7 sum: 9\n",
      "Partition 8 sum: 15\n",
      "Partition 9 sum: 0\n",
      "Partition 10 sum: 7\n",
      "Partition 11 sum: 15\n",
      "Partition 12 sum: 24\n",
      "Partition 13 sum: 34\n"
     ]
    }
   ],
   "source": [
    "numbers_rdd = sc.parallelize(range(1, 11), numSlices=3)\n",
    "print(numbers_rdd.glom().collect())\n",
    "#print(numbers_rdd.collect())\n",
    "# Define the binary operator for summation\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "# Perform fold operation on each partition to get sum of each partition\n",
    "partition_sums = numbers_rdd.mapPartitions(lambda partition: [folded_result := 0] + [folded_result := add(folded_result, num) for num in partition])\n",
    "\n",
    "# Collect the partition sums as a list\n",
    "partition_sums_list = partition_sums.collect()\n",
    "\n",
    "# Print the sum of each partition\n",
    "for i, partition_sum in enumerate(partition_sums_list):\n",
    "    print(f\"Partition {i + 1} sum:\", partition_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b43c799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values x_map:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Values y_map:[(1, 1), (2, 4), (3, 9), (4, 16), (5, 25), (6, 36), (7, 49), (8, 64), (9, 81), (10, 100)]\n"
     ]
    }
   ],
   "source": [
    "x_map = sc.parallelize(range(1,11))\n",
    "y_map = x_map.map(lambda x:(x,x**2))\n",
    "print('Values x_map:{0}'.format(x_map.collect()))\n",
    "print('Values y_map:{0}'.format(y_map.collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d808cda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values x_filter:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Values y_filter:[2, 4, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "x_filter = sc.parallelize(range(1,11))\n",
    "y_filter = x_map.filter(lambda x:x%2 == 0)\n",
    "print('Values x_filter:{0}'.format(x_filter.collect()))\n",
    "print('Values y_filter:{0}'.format(y_filter.collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd4cef17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6]]\n",
      "[[6], [15]]\n"
     ]
    }
   ],
   "source": [
    "x_mapPartition = sc.parallelize([1,2,3,4,5,6],2)\n",
    "def f(iterator): yield sum(iterator)\n",
    "y_mapPartition= x_mapPartition.mapPartitions(f)\n",
    "#glom() flattens elements of the same partition\n",
    "print(x_mapPartition.glom().collect())\n",
    "print(y_mapPartition.glom().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cb59eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('B', <pyspark.resultiterable.ResultIterable object at 0x7f2115df4ee0>), ('A', <pyspark.resultiterable.ResultIterable object at 0x7f2115df4f40>), ('C', <pyspark.resultiterable.ResultIterable object at 0x7f2115df4e20>)]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m y_gb\u001b[38;5;241m=\u001b[39m x_gb\u001b[38;5;241m.\u001b[39mgroupByKey()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_gb\u001b[38;5;241m.\u001b[39mcollect())\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m([(j[\u001b[38;5;241m0\u001b[39m],[i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m j[i]]) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m y_gb\u001b[38;5;241m.\u001b[39mcollect()])\n",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m y_gb\u001b[38;5;241m=\u001b[39m x_gb\u001b[38;5;241m.\u001b[39mgroupByKey()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_gb\u001b[38;5;241m.\u001b[39mcollect())\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m([(j[\u001b[38;5;241m0\u001b[39m],[i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m]) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m y_gb\u001b[38;5;241m.\u001b[39mcollect()])\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "#groupByKey\n",
    "x_gb= sc.parallelize([('B',5),('B',4),('A',3),('A',2),('C',3)])\n",
    "y_gb= x_gb.groupByKey()\n",
    "print(y_gb.collect())\n",
    "print([(j[0],[i for i in j[i]]) for j in y_gb.collect()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a08115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spark Caching and Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "003df5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchDayResults_rdd = sc.textFile(\"/home/desai/DE/Files/pl_stats_2023/2023_matchday_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a66f3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0.38904363699975875\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "start=timeit.default_timer()\n",
    "matchDayResults_rdd.count()\n",
    "matchDayResults_rdd.min()\n",
    "matchDayResults_rdd.max()\n",
    "matchDayResults_rdd.collect()\n",
    "end=timeit.default_timer()\n",
    "print(\"elapsed time: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8df0c07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/home/desai/DE/Files/pl_stats_2023/2023_matchday_results.csv MapPartitionsRDD[26] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchDayResults_rdd.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1a6c73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0.3070466670001224\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "start=timeit.default_timer()\n",
    "matchDayResults_rdd.count()\n",
    "matchDayResults_rdd.min()\n",
    "matchDayResults_rdd.max()\n",
    "matchDayResults_rdd.collect()\n",
    "end=timeit.default_timer()\n",
    "print(\"elapsed time: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af89b997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/home/desai/DE/Files/pl_stats_2023/2023_matchday_results.csv MapPartitionsRDD[26] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchDayResults_rdd.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e641ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/home/desai/DE/Files/pl_stats_2023/2023_matchday_results.csv MapPartitionsRDD[26] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "matchDayResults_rdd.persist(pyspark.StorageLevel.DISK_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec822dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Broadcast Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce0f5c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joins \n",
    "#join\n",
    "#leftOuterJoin\n",
    "#rightOuterJoin\n",
    "#cartesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e73aa077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#difference between rdd & dataframe & dataset\n",
    "#Test\n",
    "#Test123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd1faa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
